{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install tensorflow==1.15.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tensorflow.contrib.layers import conv2d, avg_pool2d, max_pool2d\n",
    "from tensorflow.contrib.layers import batch_norm, l2_regularizer\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters of squeezeNet\n",
    "\n",
    "img_height = 224\n",
    "img_width = 224\n",
    "img_channel = 3\n",
    "batch_size = 16\n",
    "max_iter = 4000\n",
    "lr = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting train data\n",
    "\n",
    "train_text_file = pd.read_csv(\"./annotations/train_labels.csv\")\n",
    "\n",
    "train_images = []\n",
    "train_labels = []\n",
    "for i, row in train_text_file.iterrows():\n",
    "#     print(i)\n",
    "    if (row['class_id']<10):\n",
    "        image_name = row['image_name']\n",
    "        img = cv2.imread(image_name)\n",
    "        img1 =cv2.resize(img, (img_height, img_width))\n",
    "        norm_image = cv2.normalize(img1, None, alpha=0, beta=1, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_32F)\n",
    "#         print(norm_image)\n",
    "    #     cv2.imshow(\"img\", img)\n",
    "    #     cv2.waitKey(100)\n",
    "        train_images.append(norm_image)\n",
    "        train_labels.append(row['class_id'])\n",
    "train_images = np.array(train_images)\n",
    "train_labels = np.array(train_labels)\n",
    "train_labels = np.resize(train_labels, (train_labels.shape[0],1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting test data\n",
    "test_text_file = pd.read_csv(\"./annotations/test_labels.csv\")\n",
    "test_images = []\n",
    "test_labels = []\n",
    "for i, row in test_text_file.iterrows():\n",
    "#     print(i)\n",
    "    if (row['class_id']<10):\n",
    "        image_name = row['image_name']\n",
    "        img = cv2.imread(image_name)\n",
    "        img1 =cv2.resize(img, (img_height, img_width))\n",
    "        norm_image = cv2.normalize(img1, None, alpha=0, beta=1, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_32F)\n",
    "\n",
    "    #     cv2.imshow(\"img\", img)\n",
    "    #     cv2.waitKey(100)\n",
    "        test_images.append(norm_image)\n",
    "        test_labels.append(row['class_id'])\n",
    "test_images = np.array(test_images)\n",
    "test_labels = np.array(test_labels)\n",
    "test_labels = np.resize(test_labels, (test_labels.shape[0],1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images.shape, train_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_images.shape, test_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fire module in squeezeNet\n",
    "\n",
    "def fire(inputs1, squeeze_op, expand_op1, expand_op2 , scope=None):\n",
    "    with tf.variable_scope(scope, 'fire'):\n",
    "        net1 = conv2d(inputs1, squeeze_op, [1, 1], stride=1, scope='squeeze')\n",
    "        e1 = conv2d(net1, expand_op1, [1, 1], stride=1, scope='1x1')\n",
    "        e3 = conv2d(net1, expand_op2, [3, 3], scope='3x3')\n",
    "    return tf.concat([e1, e3], 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/tensorflow/docs/blob/r1.14/site/en/api_docs/python/tf/contrib/layers/conv2d.md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining squeezeNet architecture\n",
    "\n",
    "def SqueezeNet(inputs, num_classes):\n",
    "    with tf.variable_scope(\"squeezenet\"):\n",
    "        net = conv2d(inputs, 96, [7, 7], stride=2, scope='conv1')\n",
    "        print(net.name, net.get_shape().as_list())\n",
    "        net = max_pool2d(net, [3, 3], stride=2, scope='maxpool1')\n",
    "        print(net.name, net.get_shape().as_list())\n",
    "        net = fire(net, 16, 64, 64, scope='fire2')\n",
    "        print(net.name, net.get_shape().as_list())\n",
    "        net = fire(net, 16, 64, 64, scope='fire3')\n",
    "        print(net.name, net.get_shape().as_list())\n",
    "        net = fire(net, 32, 128, 128,scope='fire4')\n",
    "        print(net.name, net.get_shape().as_list())\n",
    "        net = max_pool2d(net, [3, 3], stride=2, scope='maxpool4')\n",
    "        print(net.name, net.get_shape().as_list())\n",
    "        net = fire(net, 32, 128, 128, scope='fire5')\n",
    "        print(net.name, net.get_shape().as_list())\n",
    "        net = fire(net, 48, 192, 192, scope='fire6')\n",
    "        print(net.name, net.get_shape().as_list())\n",
    "        net = fire(net, 48, 192, 192, scope='fire7')\n",
    "        print(net.name, net.get_shape().as_list())\n",
    "        net = fire(net, 64, 256, 256, scope='fire8')\n",
    "        print(net.name, net.get_shape().as_list())\n",
    "        net = max_pool2d(net, [3, 3], stride=2, scope='maxpool8')\n",
    "        print(net.name, net.get_shape().as_list())\n",
    "        net = fire(net, 64, 256, 256, scope='fire9')\n",
    "        print(net.name, net.get_shape().as_list())\n",
    "        net = conv2d(net, num_classes, [1, 1], stride=1, scope='conv10')\n",
    "        print(net.name, net.get_shape().as_list())\n",
    "        net_shape = net.get_shape().as_list()\n",
    "#         net = avg_pool2d(net, [13, 13], stride=1, scope='avgpool10')\n",
    "        net = avg_pool2d(net, [net_shape[1],net_shape[1]], stride=1, scope='avgpool10')\n",
    "        print(net.name, net.get_shape().as_list())\n",
    "        \n",
    "        net = tf.squeeze(net, [2], name='logits')\n",
    "        print(net.name, net.get_shape().as_list())\n",
    "        return net\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function for iterating through mini-batches of the data\n",
    "def batch_generator(n_iter, X, y,  batch_size=16, \n",
    "                    shuffle=False, random_seed=None):\n",
    "    batch_nos = [i for i in range(0, X.shape[0], batch_size)]\n",
    "    i = int((n_iter%len(batch_nos)))\n",
    "#     print(\"batch : \", i)\n",
    "    if shuffle:  # shuffles sample order in output batch\n",
    "        \n",
    "        i = np.random.choice(batch_nos)\n",
    "#     print(\"batch : \", i)\n",
    "    return X[i:i+batch_size, :], y[i:i+batch_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining placeholders\n",
    "\n",
    "# Initialize placeholders \n",
    "x = tf.placeholder(dtype = tf.float32, shape = [None, img_height, img_width, img_channel])\n",
    "y = tf.placeholder(dtype = tf.int32, shape = [None,1])\n",
    "# logits = tf.placeholder(dtype = tf.int32, shape = [None,1,1,num_classes])\n",
    "\n",
    "\n",
    "logits = SqueezeNet(x,num_classes)\n",
    "# Define a loss function\n",
    "loss = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(labels = y, \n",
    "                                                                    logits = logits))\n",
    "# Define an optimizer \n",
    "train_op = tf.train.AdamOptimizer(learning_rate=lr).minimize(loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training the squeezeNet\n",
    "\n",
    "tf.set_random_seed(1234)\n",
    "sess = tf.Session()\n",
    "\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "for i in range(max_iter):\n",
    "#         print('EPOCH', i)\n",
    "        input_images, input_labels = batch_generator(i, train_images, train_labels, batch_size, shuffle=True)\n",
    "#         print(input_images.shape, input_labels.shape)\n",
    "        logits1, op, iter_loss = sess.run([logits, train_op, loss], feed_dict={x: input_images, y: input_labels})\n",
    "    \n",
    "        if i % 10 == 0:\n",
    "#             print(input_images.shape)\n",
    "#             print(np.array(logits1).shape)\n",
    "            pred = np.argmax(logits1, 2)\n",
    "#             print(\"pred : \", pred)\n",
    "#             print(\"logits1 : \", logits1)\n",
    "#             print(\"actual : \", input_labels)\n",
    "            acc= accuracy_score(input_labels, pred)\n",
    "            print(\"Loss: \", iter_loss, \"acc : \", acc)\n",
    "saver = tf.train.Saver()\n",
    "saver.save(sess, \"./model_ckpt/squeezenet.ckpt\")\n",
    "#         print('DONE WITH EPOCH')\n",
    "\n",
    "\n",
    "pred_test = []\n",
    "for i in range(test_images.shape[0]):\n",
    "    logits1 = sess.run([logits], feed_dict={x: np.resize(test_images[i], (1,img_height, img_width, img_channel))})\n",
    "#     print(np.array(logits1).shape)\n",
    "#     print(np.resize(test_images[i], (1,img_height, img_width, img_channel)).shape)\n",
    "    pred = np.argmax(logits1,3)\n",
    "    pred_test.append(pred[0][0][0])\n",
    "acc= accuracy_score(test_labels, pred_test)\n",
    "print(\"test accuracy : \", acc)\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
